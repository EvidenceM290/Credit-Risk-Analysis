---

# **ğŸ“Š Credit Risk Analysis: Predicting Loan Defaults**  

## ğŸš€ **Project Overview**  
This project analyzes **loan applicant data** to predict **default risk** using **two classification models**:  
1. **Logistic Regression**  
2. **Decision Tree**  

By leveraging **financial history, demographic features, and past repayments**, we can help financial institutions **identify high-risk borrowers** and make informed lending decisions.

ğŸ“Œ **Key Highlights**
- ğŸ¦ **Business Problem:** Improve loan approval strategies by identifying risky applicants.
- ğŸ” **Feature Engineering:** Data cleaning, handling missing values, and variable transformation.
- ğŸ† **Modeling Approach:** Logistic Regression & Decision Tree.
- ğŸ“Š **Evaluation Metrics:** Accuracy, Precision, Recall, AUC (ROC Curve), True Positive Rate.

---

## **ğŸ“‚ Project Structure**
```
ğŸ“‚ credit-risk-analysis/
 â”œâ”€â”€ ğŸ“‚ data/ (Datasets)
 â”‚   â”œâ”€â”€ loan_data.csv *(Raw data file)*
 â”‚   â”œâ”€â”€ processed_loan_data.csv *(Cleaned dataset)*
 â”‚  
 â”œâ”€â”€ ğŸ“‚ notebooks/ *(Jupyter Notebooks & R scripts for model building)*
 â”‚   â”œâ”€â”€ credit_risk_analysis.ipynb *(Exploratory Data Analysis & Model Training)*
 â”‚   â”œâ”€â”€ model_evaluation.ipynb *(Confusion Matrix, ROC Curve, AUC computation)*
 â”‚  
 â”œâ”€â”€ ğŸ“‚ images/ *(Screenshots & visualizations for better insights)*
 â”‚   â”œâ”€â”€ Modelflow.png *(KNIME Workflow Overview)*
 â”‚   â”œâ”€â”€ Decision Model Metrics.png *(Decision Tree Model Performance)*
 â”‚   â”œâ”€â”€ Logit model-metrics.png *(Logistic Regression Model Performance)*
 â”‚   â”œâ”€â”€ Decision Tree ROC Curve.png *(ROC Curve for Decision Tree)*
 â”‚   â”œâ”€â”€ Logit ROC Curve.png *(ROC Curve for Logistic Regression)*
 â”‚   â”œâ”€â”€ Admission by rank.png *(Admission Rate by School Rank)*
 â”‚   â”œâ”€â”€ Distribution of GRE.png *(GRE Score Distribution)*
 â”‚   â”œâ”€â”€ GPA Distribution.png *(GPA Score Distribution)*
 â”‚  
 â”œâ”€â”€ ğŸ“‚ models/ *(Stored trained models if applicable)*
 â”‚   â”œâ”€â”€ decision_tree_model.pkl *(Trained Decision Tree Model)*
 â”‚   â”œâ”€â”€ logistic_regression_model.pkl *(Trained Logistic Model)*
 â”‚  
 â”œâ”€â”€ ğŸ“œ README.md *(Project documentation and guide)*
 â”œâ”€â”€ ğŸ“œ requirements.txt *(Python dependencies)*
```

---

## **ğŸ“Œ Workflow Overview**
This **KNIME Workflow** outlines the complete **data preprocessing, model training, and evaluation process**.

![Workflow](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Modelflow.png)

---

## **ğŸ“ˆ Results & Visualizations**
### **1ï¸âƒ£ Model Performance Metrics**
#### **ğŸ”¹ Decision Tree Model Performance**
The **Decision Tree Model** had a **True Positive Rate of 37.5%**, meaning it identified **more actual defaults** compared to Logistic Regression.

ğŸ“Œ **Confusion Matrix & Metrics**:  
![Decision Tree Metrics](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Decision%20Model%20Metrics.png)

---

#### **ğŸ”¹ Logistic Regression Model Performance**
The **Logistic Regression Model** had a **True Positive Rate of only 18.8%**, meaning it struggled to correctly classify actual defaults.

ğŸ“Œ **Confusion Matrix & Metrics**:  
![Logistic Regression Metrics](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Logit%20model-metrics.png)

---

### **2ï¸âƒ£ ROC Curve Analysis**
#### **ğŸ”¹ Decision Tree ROC Curve**
The **Decision Tree Model achieved an AUC score of 0.592**, showing moderate predictive power.

![Decision Tree ROC](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Decision%20Tree%20ROC%20Curve.png)

#### **ğŸ”¹ Logistic Regression ROC Curve**
The **Logistic Regression Model had an AUC score of 0.665**, performing slightly better at differentiating defaults.

![Logistic Regression ROC](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Logit%20ROC%20Curve.png)

---

### **3ï¸âƒ£ Admission Insights**
The **bar chart below shows admission rates by school rank**. **Higher-ranked schools (Rank 1) have a significantly higher admission rate (54.1%)** compared to lower-ranked schools (17.9% for Rank 4).

ğŸ“Œ **Admission Rate by School Rank**:  
![Admission by Rank](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Admission%20by%20rank.png)

---

### **4ï¸âƒ£ Feature Distributions**
#### **ğŸ”¹ GRE Score Distribution**
This histogram shows the distribution of **GRE scores** in the dataset. It appears **slightly right-skewed**, indicating more high GRE scores.

![GRE Distribution](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/Distribution%20of%20GRE.png)

#### **ğŸ”¹ GPA Score Distribution**
The **GPA scores** are also **right-skewed**, with a concentration of students having high GPAs.

![GPA Distribution](https://raw.githubusercontent.com/EvidenceM290/credit-risk-analysis/main/images/GPA%20Distribution.png)

---

## **ğŸ”¹ Key Takeaways**
âœ” **Decision Tree Model** is **better at predicting actual defaults (37.5% True Positive Rate) than Logistic Regression (18.8%)**.  
âœ” **Logistic Regression** has **higher AUC (0.665) than Decision Tree (0.592)**, meaning itâ€™s slightly better at ranking high-risk applicants.  
âœ” **Admission rates drop significantly for lower-ranked schools**, impacting acceptance chances.  
âœ” **GRE and GPA distributions are skewed**, indicating high competition among applicants.  

---

---

## **ğŸ“¬ Connect With Me**
ğŸ“§ **Email:** emadhume@smu.edu  
ğŸ”— **LinkedIn:** [Your Profile](your-linkedin-url)  
ğŸ“‚ **GitHub Portfolio:** [Your GitHub](your-github-url)

---


